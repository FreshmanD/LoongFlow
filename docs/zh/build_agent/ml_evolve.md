# ML Evolve Agent

ML Evolve Agent æ˜¯ LoongFlow æ¡†æ¶ä¸­ä¸“é—¨ç”¨äºè‡ªåŠ¨åŒ–æœºå™¨å­¦ä¹ çš„æ™ºèƒ½ä½“ï¼Œä¸“æ³¨äºè§£å†³ Kaggle é£æ ¼çš„ç«èµ›å’Œ MLE-Bench é—®é¢˜ã€‚

## ğŸ—ï¸ æ¶æ„æ¦‚è¿°

ML Evolve Agent é‡‡ç”¨è¿›åŒ–ç®—æ³•æ¡†æ¶ï¼ŒåŒ…å«ä»¥ä¸‹æ ¸å¿ƒç»„ä»¶ï¼š

```mermaid
graph TB
    P[ML Planner] --> EC[Evocoder]
    EC --> EX[ML Executor]
    EX --> EV[ML Evaluator]
    EV --> S[ML Summary]
    S --> M[Memory]
    M --> P
```

### æ ¸å¿ƒç»„ä»¶åŠŸèƒ½

**ML Planner** - æœºå™¨å­¦ä¹ è§„åˆ’å™¨
- åˆ†ææ•°æ®é›†ç‰¹å¾å’Œä»»åŠ¡éœ€æ±‚
- åˆ¶å®šæœºå™¨å­¦ä¹ ç®¡é“ç­–ç•¥
- ç¡®å®šç‰¹å¾å·¥ç¨‹å’Œæ¨¡å‹é€‰æ‹©æ–¹æ¡ˆ

**Evocoder** - ä»£ç ç”Ÿæˆå™¨
- æŒ‰é˜¶æ®µç”Ÿæˆæœºå™¨å­¦ä¹ ä»£ç 
- æ”¯æŒæ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒã€é¢„æµ‹ç­‰æ¨¡å—
- é€šè¿‡è¯„ä¼°å™¨éªŒè¯ä»£ç å¯æ‰§è¡Œæ€§

**ML Executor** - æ‰§è¡Œå™¨
- è¿è¡Œç”Ÿæˆçš„æœºå™¨å­¦ä¹ ç®¡é“
- ç®¡ç† GPU/CPU èµ„æºåˆ†é…
- å¤„ç†å¤§è§„æ¨¡æ•°æ®é›†è®­ç»ƒ

**ML Evaluator** - è¯„ä¼°å™¨
- æ‰§è¡Œè¯„ä¼°å‡½æ•°è®¡ç®—æ¨¡å‹æ€§èƒ½
- éªŒè¯é¢„æµ‹ç»“æœå’Œæäº¤æ ¼å¼
- åœ¨ç‹¬ç«‹è¿›ç¨‹ä¸­ç¡®ä¿å®‰å…¨æ‰§è¡Œ

**ML Summary** - æ€»ç»“å™¨
- åˆ†æè¿­ä»£ç»“æœå’Œæ€§èƒ½æŒ‡æ ‡
- ç”Ÿæˆæ”¹è¿›å»ºè®®å’Œå­¦ä¹ æ´å¯Ÿ

## ?? å¿«é€Ÿå¼€å§‹

### è¿è¡Œç¤ºä¾‹ä»»åŠ¡

```bash
# åˆå§‹åŒ–ç¯å¢ƒ
./run_ml.sh init

# è¿è¡Œ Iris åˆ†ç±»ç¤ºä¾‹
./run_ml.sh run ml_example --background

# ç›‘æ§è¿›åº¦
tail -f output/logs/evolux.log

# åœæ­¢ä»»åŠ¡
./run_ml.sh stop ml_example
```

### ä»»åŠ¡é…ç½®ç¤ºä¾‹

åˆ›å»º `task_config.yaml` é…ç½®æ–‡ä»¶ï¼š

```yaml
workspace_path: "./output"

# LLM é…ç½®ï¼ˆå¿…éœ€ï¼‰
llm_config:
  url: "https://your-llm-api/v1"
  api_key: "your-api-key"
  model: "deepseek-v3"
  temperature: 0.8
  context_length: 128000
  max_tokens: 32768

# ç»„ä»¶é…ç½®
planners:
  ml_planner:
    react_max_steps: 10
    evo_coder_timeout: 3600

executors:
  ml_executor:
    react_max_steps: 10
    evo_coder_timeout: 43200  # 12å°æ—¶

summarizers:
  ml_summary:
    react_max_steps: 10

# è¿›åŒ–é…ç½®
evolve:
  planner_name: "ml_planner"
  executor_name: "ml_executor"
  summary_name: "ml_summary"
  max_iterations: 100
  target_score: 1.0
  evaluator:
    timeout: 1800
```

## ğŸ“ ä»»åŠ¡ç›®å½•ç»“æ„

åˆ›å»ºè‡ªå®šä¹‰æœºå™¨å­¦ä¹ ä»»åŠ¡ï¼š

```
your_ml_task/
â”œâ”€â”€ task_config.yaml        # ä»»åŠ¡é…ç½®
â”œâ”€â”€ eval_program.py         # è¯„ä¼°å‡½æ•°
â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ description.md      # ä»»åŠ¡æè¿°ï¼ˆæ™ºèƒ½ä½“å¯è§ï¼‰
â”‚   â”œâ”€â”€ train.csv           # è®­ç»ƒæ•°æ®
â”‚   â”œâ”€â”€ test.csv            # æµ‹è¯•ç‰¹å¾
â”‚   â””â”€â”€ sample_submission.csv
â””â”€â”€ private/
    â””â”€â”€ answer.csv          # çœŸå®æ ‡ç­¾ï¼ˆæ™ºèƒ½ä½“ä¸å¯è§ï¼‰
```

### è¯„ä¼°å‡½æ•°æ¨¡æ¿

```python
# eval_program.py
def evaluate(task_data_path: str, best_code_path: str, artifacts: dict) -> dict:
    """
    è¯„ä¼°æœºå™¨å­¦ä¹ è§£å†³æ–¹æ¡ˆ
    
    è¿”å›:
        dict åŒ…å«: status, summary, score(0.0-1.0), metrics, artifacts
    """
    import pandas as pd
    from sklearn.metrics import accuracy_score
    
    # åŠ è½½çœŸå®æ ‡ç­¾
    answers = pd.read_csv(f"{task_data_path}/private/answer.csv")
    
    # åŠ è½½æ™ºèƒ½ä½“ç”Ÿæˆçš„é¢„æµ‹ç»“æœ
    predictions = load_predictions(best_code_path)
    
    # è®¡ç®—æŒ‡æ ‡
    accuracy = accuracy_score(answers['target'], predictions)
    
    return {
        "status": "success",
        "summary": f"æ¨¡å‹å‡†ç¡®ç‡: {accuracy:.4f}",
        "score": accuracy,
        "metrics": {"accuracy": accuracy},
        "artifacts": artifacts
    }
```

## ğŸ”§ é«˜çº§é…ç½®

### GPU èµ„æºä¼˜åŒ–

```yaml
# åœ¨ task_config.yaml ä¸­ä¼˜åŒ– GPU ä½¿ç”¨
ml_executor:
  use_gpu: true
  batch_size: 32
  mixed_precision: true
```

### ç«äº‰ä»»åŠ¡ç‰¹å®šè®¾ç½®

```yaml
evolve:
  competition_type: "classification"  # åˆ†ç±»/å›å½’/æ’åº
  evaluation_metric: "accuracy"       # ä¸»è¦ä¼˜åŒ–æŒ‡æ ‡
  time_budget: 86400                 # æ—¶é—´é™åˆ¶(ç§’)
```

## ğŸ“Š è¾“å‡ºç»“æ„

ä»»åŠ¡å®Œæˆåï¼Œç»“æœä¿å­˜åœ¨ `output/` ç›®å½•ï¼š

```
output/
â”œâ”€â”€ <task-uuid>/
â”‚   â””â”€â”€ <iteration-id>/      # æ¯æ¬¡è¿­ä»£
â”‚       â”œâ”€â”€ planner/         # è§„åˆ’ç»“æœ
â”‚       â”œâ”€â”€ evocoder/        # ç”Ÿæˆä»£ç 
â”‚       â”œâ”€â”€ executor/        # æ‰§è¡Œç»“æœ
â”‚       â””â”€â”€ summary/         # æ€»ç»“åˆ†æ
â”œâ”€â”€ logs/                    # è¿è¡Œæ—¥å¿—
â”œâ”€â”€ database/                # æ£€æŸ¥ç‚¹å’Œè§£å†³æ–¹æ¡ˆ
â””â”€â”€ evaluate/                # è¯„ä¼°ç»“æœ
```

## ğŸ¯ æœ€ä½³å®è·µ

### æ•°æ®å‡†å¤‡
1. **æ•°æ®æ¢ç´¢**: ç¡®ä¿æ•°æ®é›†è´¨é‡è‰¯å¥½
2. **ç‰¹å¾éªŒè¯**: é¿å…æ•°æ®æ³„éœ²
3. **äº¤å‰éªŒè¯**: ä½¿ç”¨åˆé€‚çš„éªŒè¯ç­–ç•¥

### æ¨¡å‹å¼€å‘
1. **åŸºå‡†æ¨¡å‹**: ä»ç®€å•æ¨¡å‹å¼€å§‹
2. **æ¸è¿›æ”¹è¿›**: é€æ­¥å¢åŠ å¤æ‚æ€§
3. **é›†æˆç­–ç•¥**: ç»„åˆå¤šä¸ªæ¨¡å‹ç±»å‹

### æ•…éšœæ’æŸ¥
- **è¿‡æ‹Ÿåˆ**: å¢åŠ éªŒè¯ä¸¥æ ¼æ€§ï¼Œä½¿ç”¨æ—©åœ
- **èµ„æºé™åˆ¶**: ä¼˜åŒ–æ‰¹å¤§å°ï¼Œä½¿ç”¨å†…å­˜é«˜æ•ˆæ•°æ®ç±»å‹
- **è¯„ä¼°å¤±è´¥**: æ£€æŸ¥æ•°æ®æ ¼å¼å’Œè¯„ä¼°å‡½æ•°

## ğŸ”„ MLE-Bench é›†æˆ

ML Evolve Agent å®Œæ•´æ”¯æŒ MLE-Bench ç«èµ›ï¼š

```bash
# åˆå§‹åŒ– MLE-Bench ç¯å¢ƒ
./run_mlebench.sh init

# å‡†å¤‡ç«èµ›æ•°æ®
./run_mlebench.sh prepare detecting-insults-in-social-commentary

# è¿è¡Œç«èµ›
./run_mlebench.sh run detecting-insults-in-social-commentary --background
```

ML Evolve Agent æä¾›äº†ä¸€ä¸ªå®Œæ•´çš„è‡ªåŠ¨åŒ–æœºå™¨å­¦ä¹ è§£å†³æ–¹æ¡ˆï¼Œç‰¹åˆ«é€‚ç”¨äºæ•°æ®ç§‘å­¦ç«èµ›å’Œç«¯åˆ°ç«¯çš„æœºå™¨å­¦ä¹ ä»»åŠ¡ã€‚