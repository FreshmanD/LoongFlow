# 常见问题

## 入门指南


### 🔧 可以使用自己的LLM吗？

**支持所有OpenAI兼容的API**：
- 商业版：OpenAI、Google（Gemini系列）
- 本地部署：vLLM、sglang、Ollama

```yaml
llm_config:
  url: "https://your-endpoint.com/v1"
  api_key: "your-api-key"
  model: "your-model-name"
```

### 🐍 为什么需要Python 3.12+？

Python 3.12提供关键特性：
- 增强的类型系统和错误信息
- 改进的异步性能
- 更好地支持Agent框架

---

## 框架概念

### 🆚 与OpenEvolve/AlphaEvolve有何不同？

核心区别在于**思考范式**：

| 方面 | OpenEvolve/AlphaEvolve | LoongFlow |
|------|------------------------|-----------|
| **核心抽象** | 变异-选择进化 | **PES思考范式** |
| **学习方式** | 任务特定改进 | **跨任务经验积累** |
| **推理深度** | 有限 | **结构化长程推理** |

### 🧠 PES与ReAct有何不同？

PES提供结构化改进循环：
- **规划**：深度战略思考
- **执行**：结构化实验验证  
- **总结**：系统性反思经验提取

### 📚 记忆系统如何工作？

融合多种记忆结构：
- **进化树**：跟踪解决方案谱系
- **多岛地图**：保持解决方案多样性
- **经验模式**：存储成功策略

---

## 技术问题

### ⚙️ 为什么使用UV而不是pip？

UV优势：
- **更快安装**：显著快于pip
- **更好依赖解析**：更可靠的环境
- **现代工具**：专为Python 3.12+设计

### 🚀 为什么不在PyPI上分发？

技术原因：
- **复杂依赖**：不同Agent有特定需求
- **灵活配置**：用户可定制Agent和LLM设置
- **透明度**：完整源代码访问

### 🔍 如何调试智能体？

调试步骤：
1. **检查日志**：`tail -f ./agents/.../run.log`
2. **验证LLM配置**：API可达性、配额限制
3. **检查生成代码**：查看`./output`目录

---

## 性能与扩展

### 📊 扩展性如何？

**性能特征**：
- 小问题：快速收敛（<30代）
- 中等复杂度：稳定改进（30-100代）
- 大规模优化：渐进精细化（>100代）

**资源要求**：
- 内存：约500MB基础 + 每岛约100MB
- CPU：单核足够，多核支持并行

### 🎯 适合哪些问题？

**理想问题特征**：
- 明确定义的目标和评估标准
- 需要战略推理的复杂度
- 能从迭代改进中受益

**成功案例**：
- ✅ 数学优化和发现
- ✅ 机器学习竞赛
- ✅ 算法设计改进

---

## 社区与支持

### 🤝 如何贡献？

欢迎各类贡献：
- **代码**：错误修复、新Agent实现
- **文档**：教程、使用示例
- **社区**：回答问题、分享经验

### 📞 从哪里获得帮助？

支持渠道：
- **GitHub讨论**：技术问题和社区帮助
- **Discord社区**：实时讨论协作
- **问题跟踪器**：错误报告和功能请求

---

## 高级主题

### 🎨 可以创建自定义智能体吗？

**支持自定义开发**：
1. 定义PES组件（规划器、执行器、总结器）
2. 实现必要接口
3. 配置任务特定设置
4. 测试验证

### 🔄 迁移学习如何工作？

通过记忆系统实现：
- **自动检索**：识别相关的过往经验
- **策略适应**：经验适应当前上下文
- **验证改进**：测试和优化适应策略


---

还有问题吗？加入我们的[GitHub讨论](https://github.com/baidu-baige/LoongFlow/discussions)或[Discord社区](https://discord.gg/YSfdrC8HJh)获取帮助！
